{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Warning: This tutorial is currently under development.</span>\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This tutorial will walk you through a preliminary similarity searching analysis making use of scripts in the AMOEBAE toolkit. As a simple example, we will consider the the distribution of orthologues of subunits of the Adaptor Protein (AP) 2 vesicle adaptor complex, and several other membrane-trafficking proteins, in three model eukaryotes: the plant *Arabidopsis thaliana*, the yeast *Saccharomyces cerevisiae*, the fungus *Allomyces macrogynus*, the amoeba *Dictyostelium discoideum*, and the pathogenic protist *Trypanosoma brucei*. AP-2 subunits are homologous to subunits of other AP complexes (Robinson, 2004; Hirst et al., 2011), and published work has traced their evolution among plants (Larson et al., 2019), Fungi (Barlow et al., 2014), and trypanosomatid parasites (Manna et al., 2013). Thus, the protein subunits of the AP-2 complex provide a useful test of similarity searching methods to distinguish between orthologues and paralogues, which can be compared to the results of previous comprehensive studies. The membrane trafficking proteins Sec12 (a component of the COPII vesicle coat complex), SNAP33 (a Qbc-SNARE), and Rab2 (a small GTPase) are included to further explore the potential sources of error involved in identification of orthologous proteins. The end result of running this code successfully is a spreadsheet summarizing results of similarity searches, as well as a plot summarizing the results.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "-  Perform similarity searches using the BLASTP, TBLASN, HMMer algorithms simultaneously using AMOBEAE code.\n",
    "\n",
    "-  Apply a reciprocal-best-hit search strategy using AMOEBAE code.\n",
    "\n",
    "- Practice interpreting interesting similarity search results obtained using AMOEBAE.\n",
    " \n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- MacOS or Linux operating system (or possibly a work-around on windows, although this has not been tested).\n",
    "\n",
    "- Before running this code, you will need to have set up AMOEBAE according to the instructions in the main documentation file.\n",
    "\n",
    "- The code in this notebook will take approximately <span style=\"color:red\">XXXXXX</span> minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that dependencies are installed.\n",
    "You should have already pulled the amoebae git repository to your computer as described in the main documentation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastp: 2.10.0+\n",
      " Package: blast 2.10.0, build Dec  3 2019 18:03:18\n",
      "# hmmsearch :: search profile(s) against a sequence database\n",
      "# HMMER 3.3 (Nov 2019); http://hmmer.org/\n",
      "# Copyright (C) 2019 Howard Hughes Medical Institute.\n",
      "# Freely distributed under the BSD open source license.\n",
      "# esl-sfetch :: retrieve sequence(s) from a file\n",
      "# Easel 0.46 (Nov 2019)\n",
      "# Copyright (C) 2019 Howard Hughes Medical Institute.\n",
      "# Freely distributed under the BSD open source license.\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "IQ-TREE multicore version 1.6.12 for Linux 64-bit built Aug 15 2019\n",
      "Developed by Bui Quang Minh, Nguyen Lam Tung, Olga Chernomor,\n",
      "Heiko Schmidt, Dominik Schrempf, Michael Woodhams.\n",
      "\n",
      "Usage: iqtree -s <alignment> [OPTIONS]\n",
      "\n",
      "GENERAL OPTIONS:\n",
      "  -? or -h             Print this help dialog\n",
      "  -version             Display version number\n",
      "  -s <alignment>       Input alignment in PHYLIP/FASTA/NEXUS/CLUSTAL/MSF format\n",
      "  -st <data_type>      BIN, DNA, AA, NT2AA, CODON, MORPH (default: auto-detect)\n",
      "  -q <partition_file>  Edge-linked partition model (file in NEXUS/RAxML format)\n",
      " -spp <partition_file> Like -q option but allowing partition-specific rates\n",
      "  -sp <partition_file> Edge-unlinked partition model (like -M option of RAxML)\n",
      "  -t <start_tree_file> or -t BIONJ or -t RANDOM\n",
      "                       Starting tree (default: 99 parsimony tree and BIONJ)\n",
      "  -te <user_tree_file> Like -t but fixing user tree (no tree search performed)\n",
      "  -o <outgroup_taxon>  Outgroup taxon name for writing .treefile\n",
      "  -pre <PREFIX>        Prefix for all output files (default: aln/partition)\n",
      "  -nt <num_threads>    Number of cores/threads or AUTO for automatic detection\n",
      "  -ntmax <max_threads> Max number of threads by -nt AUTO (default: #CPU cores)\n",
      "  -seed <number>       Random seed number, normally used for debugging purpose\n",
      "  -v, -vv, -vvv        Verbose mode, printing more messages to screen\n",
      "  -quiet               Quiet mode, suppress printing to screen (stdout)\n",
      "  -keep-ident          Keep identical sequences (default: remove & finally add)\n",
      "  -safe                Safe likelihood kernel to avoid numerical underflow\n",
      "  -mem RAM             Maximal RAM usage for memory saving mode\n",
      "  --runs NUMBER        Number of indepedent runs (default: 1)\n",
      "\n",
      "CHECKPOINTING TO RESUME STOPPED RUN:\n",
      "  -redo                Redo analysis even for successful runs (default: resume)\n",
      "  -cptime <seconds>    Minimum checkpoint time interval (default: 60 sec)\n",
      "\n",
      "LIKELIHOOD MAPPING ANALYSIS:\n",
      "  -lmap <#quartets>    Number of quartets for likelihood mapping analysis\n",
      "  -lmclust <clustfile> NEXUS file containing clusters for likelihood mapping\n",
      "  -wql                 Print quartet log-likelihoods to .quartetlh file\n",
      "\n",
      "NEW STOCHASTIC TREE SEARCH ALGORITHM:\n",
      "  -ninit <number>      Number of initial parsimony trees (default: 100)\n",
      "  -ntop <number>       Number of top initial trees (default: 20)\n",
      "  -nbest <number>      Number of best trees retained during search (defaut: 5)\n",
      "  -n <#iterations>     Fix number of iterations to stop (default: auto)\n",
      "  -nstop <number>      Number of unsuccessful iterations to stop (default: 100)\n",
      "  -pers <proportion>   Perturbation strength for randomized NNI (default: 0.5)\n",
      "  -sprrad <number>     Radius for parsimony SPR search (default: 6)\n",
      "  -allnni              Perform more thorough NNI search (default: off)\n",
      "  -g <constraint_tree> (Multifurcating) topological constraint tree file\n",
      "  -fast                Fast search to resemble FastTree\n",
      "\n",
      "ULTRAFAST BOOTSTRAP:\n",
      "  -bb <#replicates>    Ultrafast bootstrap (>=1000)\n",
      "  -bsam GENE|GENESITE  Resample GENE or GENE+SITE for partition (default: SITE)\n",
      "  -wbt                 Write bootstrap trees to .ufboot file (default: none)\n",
      "  -wbtl                Like -wbt but also writing branch lengths\n",
      "  -nm <#iterations>    Maximum number of iterations (default: 1000)\n",
      "  -nstep <#iterations> #Iterations for UFBoot stopping rule (default: 100)\n",
      "  -bcor <min_corr>     Minimum correlation coefficient (default: 0.99)\n",
      "  -beps <epsilon>      RELL epsilon to break tie (default: 0.5)\n",
      "  -bnni                Optimize UFBoot trees by NNI on bootstrap alignment\n",
      "  -j <jackknife>       Proportion of sites for jackknife (default: NONE)\n",
      "\n",
      "STANDARD NON-PARAMETRIC BOOTSTRAP:\n",
      "  -b <#replicates>     Bootstrap + ML tree + consensus tree (>=100)\n",
      "  -bc <#replicates>    Bootstrap + consensus tree\n",
      "  -bo <#replicates>    Bootstrap only\n",
      "\n",
      "SINGLE BRANCH TEST:\n",
      "  -alrt <#replicates>  SH-like approximate likelihood ratio test (SH-aLRT)\n",
      "  -alrt 0              Parametric aLRT test (Anisimova and Gascuel 2006)\n",
      "  -abayes              approximate Bayes test (Anisimova et al. 2011)\n",
      "  -lbp <#replicates>   Fast local bootstrap probabilities\n",
      "\n",
      "MODEL-FINDER:\n",
      "  -m TESTONLY          Standard model selection (like jModelTest, ProtTest)\n",
      "  -m TEST              Standard model selection followed by tree inference\n",
      "  -m MF                Extended model selection with FreeRate heterogeneity\n",
      "  -m MFP               Extended model selection followed by tree inference\n",
      "  -m TESTMERGEONLY     Find best partition scheme (like PartitionFinder)\n",
      "  -m TESTMERGE         Find best partition scheme followed by tree inference\n",
      "  -m MF+MERGE          Find best partition scheme incl. FreeRate heterogeneity\n",
      "  -m MFP+MERGE         Like -m MF+MERGE followed by tree inference\n",
      "  -rcluster <percent>  Percentage of partition pairs (relaxed clustering alg.)\n",
      "  -rclusterf <perc.>   Percentage of partition pairs (fast relaxed clustering)\n",
      "  -rcluster-max <num>  Max number of partition pairs (default: 10*#partitions)\n",
      "  -mset program        Restrict search to models supported by other programs\n",
      "                       (raxml, phyml or mrbayes)\n",
      "  -mset <lm-subset>    Restrict search to a subset of the Lie-Markov models\n",
      "                       Options for lm-subset are:\n",
      "                       liemarkov, liemarkovry, liemarkovws, liemarkovmk, strandsymmetric\n",
      "  -mset m1,...,mk      Restrict search to models in a comma-separated list\n",
      "                       (e.g. -mset WAG,LG,JTT)\n",
      "  -msub source         Restrict search to AA models for specific sources\n",
      "                       (nuclear, mitochondrial, chloroplast or viral)\n",
      "  -mfreq f1,...,fk     Restrict search to using a list of state frequencies\n",
      "                       (default AA: -mfreq FU,F; codon: -mfreq ,F1x4,F3x4,F)\n",
      "  -mrate r1,...,rk     Restrict search to a list of rate-across-sites models\n",
      "                       (e.g. -mrate E,I,G,I+G,R is used for -m MF)\n",
      "  -cmin <kmin>         Min #categories for FreeRate model [+R] (default: 2)\n",
      "  -cmax <kmax>         Max #categories for FreeRate model [+R] (default: 10)\n",
      "  -merit AIC|AICc|BIC  Optimality criterion to use (default: all)\n",
      "  -mtree               Perform full tree search for each model considered\n",
      "  -mredo               Ignore model results computed earlier (default: reuse)\n",
      "  -madd mx1,...,mxk    List of mixture models to also consider\n",
      "  -mdef <nexus_file>   A model definition NEXUS file (see Manual)\n",
      "\n",
      "SUBSTITUTION MODEL:\n",
      "  -m <model_name>\n",
      "                  DNA: HKY (default), JC, F81, K2P, K3P, K81uf, TN/TrN, TNef,\n",
      "                       TIM, TIMef, TVM, TVMef, SYM, GTR, or 6-digit model\n",
      "                       specification (e.g., 010010 = HKY)\n",
      "              Protein: LG (default), Poisson, cpREV, mtREV, Dayhoff, mtMAM,\n",
      "                       JTT, WAG, mtART, mtZOA, VT, rtREV, DCMut, PMB, HIVb,\n",
      "                       HIVw, JTTDCMut, FLU, Blosum62, GTR20, mtMet, mtVer, mtInv\n",
      "      Protein mixture: C10,...,C60, EX2, EX3, EHO, UL2, UL3, EX_EHO, LG4M, LG4X\n",
      "               Binary: JC2 (default), GTR2\n",
      "      Empirical codon: KOSI07, SCHN05\n",
      "    Mechanistic codon: GY (default), MG, MGK, GY0K, GY1KTS, GY1KTV, GY2K,\n",
      "                       MG1KTS, MG1KTV, MG2K\n",
      " Semi-empirical codon: XX_YY where XX is empirical and YY is mechanistic model\n",
      "       Morphology/SNP: MK (default), ORDERED, GTR\n",
      "       Lie Markov DNA: One of the following, optionally prefixed by RY, WS or MK:\n",
      "                       1.1,  2.2b, 3.3a, 3.3b,  3.3c,\n",
      "                       3.4,  4.4a, 4.4b, 4.5a,  4.5b,\n",
      "                       5.6a, 5.6b, 5.7a, 5.7b,  5.7c,\n",
      "                       5.11a,5.11b,5.11c,5.16,  6.6,\n",
      "                       6.7a, 6.7b, 6.8a, 6.8b,  6.17a,\n",
      "                       6.17b,8.8,  8.10a,8.10b, 8.16,\n",
      "                       8.17, 8.18, 9.20a,9.20b,10.12,\n",
      "                       10.34,12.12\n",
      "       Non-reversible: STRSYM (strand symmetric model, synonymous with WS6.6)\n",
      "       Non-reversible: UNREST (most general unrestricted model, functionally equivalent to 12.12)\n",
      "       Models can have parameters appended in brackets.\n",
      "           e.g. '-mRY3.4{0.2,-0.3}+I' specifies parameters for\n",
      "           RY3.4 model but leaves proportion of invariant sites\n",
      "           unspecified. '-mRY3.4{0.2,-0.3}+I{0.5} gives both.\n",
      "           When this is done, the given parameters will be taken\n",
      "           as fixed (default) or as start point for optimization\n",
      "           (if -optfromgiven option supplied)\n",
      "\n",
      "        Otherwise: Name of file containing user-model parameters\n",
      "                   (rate parameters and state frequencies)\n",
      "\n",
      "STATE FREQUENCY:\n",
      "  Append one of the following +F... to -m <model_name>\n",
      "  +F                   Empirically counted frequencies from alignment\n",
      "  +FO (letter-O)       Optimized frequencies by maximum-likelihood\n",
      "  +FQ                  Equal frequencies\n",
      "  +FRY, +FWS, +FMK     For DNA models only, +FRY is freq(A+G)=1/2=freq(C+T),\n",
      "                       +FWS is freq(A+T)=1/2=freq(C+G), +FMK is freq(A+C)=1/2=freq(G+T).\n",
      "  +F####               where # are digits - for DNA models only, for basis in ACGT order,\n",
      "                       digits indicate which frequencies are constrained to be the same.\n",
      "                       E.g. +F1221 means freq(A)=freq(T), freq(C)=freq(G).\n",
      "  +FU                  Amino-acid frequencies by the given protein matrix\n",
      "  +F1x4 (codon model)  Equal NT frequencies over three codon positions\n",
      "  +F3x4 (codon model)  Unequal NT frequencies over three codon positions\n",
      "\n",
      "MIXTURE MODEL:\n",
      "  -m \"MIX{model1,...,modelK}\"   Mixture model with K components\n",
      "  -m \"FMIX{freq1,...freqK}\"     Frequency mixture model with K components\n",
      "  -mwopt               Turn on optimizing mixture weights (default: none)\n",
      "\n",
      "RATE HETEROGENEITY AMONG SITES:\n",
      "  -m modelname+I       A proportion of invariable sites\n",
      "  -m modelname+G[n]    Discrete Gamma model with n categories (default n=4)\n",
      "  -m modelname*G[n]    Discrete Gamma model with unlinked model parameters\n",
      "  -m modelname+I+G[n]  Invariable sites plus Gamma model with n categories\n",
      "  -m modelname+R[n]    FreeRate model with n categories (default n=4)\n",
      "  -m modelname*R[n]    FreeRate model with unlinked model parameters\n",
      "  -m modelname+I+R[n]  Invariable sites plus FreeRate model with n categories\n",
      "  -m modelname+Hn      Heterotachy model with n classes\n",
      "  -m modelname*Hn      Heterotachy model with n classes and unlinked parameters\n",
      "  -a <Gamma_shape>     Gamma shape parameter for site rates (default: estimate)\n",
      "  -amin <min_shape>    Min Gamma shape parameter for site rates (default: 0.02)\n",
      "  -gmedian             Median approximation for +G site rates (default: mean)\n",
      "  --opt-gamma-inv      More thorough estimation for +I+G model parameters\n",
      "  -i <p_invar>         Proportion of invariable sites (default: estimate)\n",
      "  -wsr                 Write site rates to .rate file\n",
      "  -mh                  Computing site-specific rates to .mhrate file using\n",
      "                       Meyer & von Haeseler (2003) method\n",
      "\n",
      "POLYMORPHISM AWARE MODELS (PoMo):\n",
      " -s <counts_file>      Input counts file (see manual)\n",
      " -m <MODEL>+P          DNA substitution model (see above) used with PoMo\n",
      "   +N<POPSIZE>         Virtual population size (default: 9)\n",
      "   +[WB|WH|S]          Sampling method (default: +WB), WB: Weighted binomial,\n",
      "                       WH: Weighted hypergeometric S: Sampled sampling\n",
      "   +G[n]               Discrete Gamma rate model with n categories (default n=4)\n",
      "\n",
      "ASCERTAINMENT BIAS CORRECTION:\n",
      "  -m modelname+ASC     Correction for absence of invariant sites in alignment\n",
      "\n",
      "SINGLE TOPOLOGY HETEROTACHY MODEL:\n",
      " -m <model_name>+H[k]  Heterotachy model mixed branch lengths with k classes\n",
      " -m \"MIX{m1,...mK}+H\"\n",
      " -nni-eval <m>         Loop m times for NNI evaluation (default m=1)\n",
      "\n",
      "SITE-SPECIFIC FREQUENCY MODEL:\n",
      "  -ft <tree_file>      Input tree to infer site frequency model\n",
      "  -fs <in_freq_file>   Input site frequency model file\n",
      "  -fmax                Posterior maximum instead of mean approximation\n",
      "\n",
      "CONSENSUS RECONSTRUCTION:\n",
      "  -t <tree_file>       Set of input trees for consensus reconstruction\n",
      "  -minsup <threshold>  Min split support in range [0,1]; 0.5 for majority-rule\n",
      "                       consensus (default: 0, i.e. extended consensus)\n",
      "  -bi <burnin>         Discarding <burnin> trees at beginning of <treefile>\n",
      "  -con                 Computing consensus tree to .contree file\n",
      "  -net                 Computing consensus network to .nex file\n",
      "  -sup <target_tree>   Assigning support values for <target_tree> to .suptree\n",
      "  -suptag <name>       Node name (or ALL) to assign tree IDs where node occurs\n",
      "\n",
      "ROBINSON-FOULDS DISTANCE:\n",
      "  -rf_all              Computing all-to-all RF distances of trees in <treefile>\n",
      "  -rf <treefile2>      Computing all RF distances between two sets of trees\n",
      "                       stored in <treefile> and <treefile2>\n",
      "  -rf_adj              Computing RF distances of adjacent trees in <treefile>\n",
      "\n",
      "TREE TOPOLOGY TEST:\n",
      "  -z <trees_file>      Evaluating a set of user trees\n",
      "  -zb <#replicates>    Performing BP,KH,SH,ELW tests for trees passed via -z\n",
      "  -zw                  Also performing weighted-KH and weighted-SH tests\n",
      "  -au                  Also performing approximately unbiased (AU) test\n",
      "\n",
      "ANCESTRAL STATE RECONSTRUCTION:\n",
      "  -asr                 Ancestral state reconstruction by empirical Bayes\n",
      "  -asr-min <prob>      Min probability of ancestral state (default: equil freq)\n",
      "\n",
      "GENERATING RANDOM TREES:\n",
      "  -r <num_taxa>        Create a random tree under Yule-Harding model\n",
      "  -ru <num_taxa>       Create a random tree under Uniform model\n",
      "  -rcat <num_taxa>     Create a random caterpillar tree\n",
      "  -rbal <num_taxa>     Create a random balanced tree\n",
      "  -rcsg <num_taxa>     Create a random circular split network\n",
      "  -rlen <min_len> <mean_len> <max_len>  \n",
      "                       min, mean, and max branch lengths of random trees\n",
      "\n",
      "MISCELLANEOUS:\n",
      "  -wt                  Write locally optimal trees into .treels file\n",
      "  -blfix               Fix branch lengths of user tree passed via -te\n",
      "  -blscale             Scale branch lengths of user tree passed via -t\n",
      "  -blmin               Min branch length for optimization (default 0.000001)\n",
      "  -blmax               Max branch length for optimization (default 100)\n",
      "  -wsr                 Write site rates and categories to .rate file\n",
      "  -wsl                 Write site log-likelihoods to .sitelh file\n",
      "  -wslr                Write site log-likelihoods per rate category\n",
      "  -wslm                Write site log-likelihoods per mixture class\n",
      "  -wslmr               Write site log-likelihoods per mixture+rate class\n",
      "  -wspr                Write site probabilities per rate category\n",
      "  -wspm                Write site probabilities per mixture class\n",
      "  -wspmr               Write site probabilities per mixture+rate class\n",
      "  -wpl                 Write partition log-likelihoods to .partlh file\n",
      "  -fconst f1,...,fN    Add constant patterns into alignment (N=#nstates)\n",
      "  -me <epsilon>        LogL epsilon for parameter estimation (default 0.01)\n",
      "  --no-outfiles        Suppress printing output files\n",
      "  --eigenlib           Use Eigen3 library\n",
      "  -alninfo             Print alignment sites statistics to .alninfo\n",
      "  -czb                 Collapse zero branches in final tree\n",
      "  --show-lh            Compute tree likelihood without optimisation\n",
      "\n",
      "\n",
      "BLASTP version:\n",
      "\n",
      "HMMer version:\n",
      "\n",
      "HMMer esl-fetch utilities:\n",
      "\n",
      "MUSCLE version:\n",
      "\n",
      "IQ-TREE version:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "amoebae check_depend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-redundant list of import statements:\n",
      "\n",
      "1. import sys  # add_seq_man.py\n",
      "2. import os  # add_seq_man.py\n",
      "3. import shutil  # add_seq_man.py\n",
      "4. import time  # add_seq_man.py\n",
      "5. from module_afa_to_nex import afa_to_nex, nex_to_afa  # add_seq_man.py\n",
      "6. from afa_to_fa import afa_to_fa  # add_seq_man.py\n",
      "7. from module_afa_to_nex import align_one_fa  # add_seq_man.py\n",
      "8. from subprocess import call  # add_seq_man.py\n",
      "9. from parse_mod_num import update_mod_num_numeric  # add_seq_man.py\n",
      "10. import subprocess  # boots_on_best_ml.py\n",
      "11. import glob  # boots_on_best_ml.py\n",
      "12. import settings  # boots_on_best_ml.py\n",
      "13. from module_amoebae_name_replace import write_newick_tree_with_uncoded_names  # boots_on_best_ml.py\n",
      "14. import re  # boots_on_mb.py\n",
      "15. from ete3 import Tree  # boots_on_mb.py\n",
      "16. from settings import raxmlname  # boots_on_mb.py\n",
      "17. from module_boots_on_mb import reformat_combined_supports, combine_supports,\\  # boots_on_mb.py\n",
      "18. mbcontre_to_newick_w_probs, contre_to_newick  # boots_on_mb.py\n",
      "19. import math  # calculate_possible_seq_sets_to_tree.py\n",
      "20. import argparse  # run_rev_srch.py\n",
      "21. import module_amoebae_run_searches  # run_rev_srch.py\n",
      "22. from module_get_fas_from_db_dir import get_seq_obj_from_db_fasta  # nex_to_full-length_fa.py\n",
      "23. from Bio import AlignIO  # nex_to_full-length_fa.py\n",
      "24. import module_afa_to_nex  # nex_to_full-length_fa.py\n",
      "25. from Bio import SeqIO  # append_afas.py\n",
      "26. from Bio.Alphabet import IUPAC, Gapped  # append_afas.py\n",
      "27. from module_afa_to_nex import afa_to_nex  # append_afas.py\n",
      "28. import itertools  # nhmmer_scaffolds.py\n",
      "29. from Bio.Seq import Seq  # nhmmer_scaffolds.py\n",
      "30. from Bio.Alphabet import IUPAC  # nhmmer_scaffolds.py\n",
      "31. import module_nhmmer_scaffolds  # nhmmer_scaffolds.py\n",
      "32. from module_paralogue_counter import count_paralogues2  # paralogue_counter2.py\n",
      "33. from module_amoebae_trim_nex import trim_nex  # trim_nex.py\n",
      "34. from misc_functions import get_fa_record_text_from_obj  # add_only_new_fas.py\n",
      "35. from Bio.SeqIO.QualityIO import FastqGeneralIterator  # convert_fastq_to_fasta.py\n",
      "36. import random  # convert_fastq_to_fasta.py\n",
      "37. from module_amoebae_name_replace import write_newick_tree_with_coded_names  # code_newick.py\n",
      "38. from module_amoebae_name_replace import codenames_nex  # codenames_nex.py\n",
      "39. from datetime import datetime  # run_snare_superfam_topology_test.py\n",
      "40. from module_amoebae_get_datatype import get_dbtype  # get_datatype.py\n",
      "41. from module_afa_to_nex import nex_to_afa, afa_to_nex  # reduce_fasta.py\n",
      "42. from module_amoebae import get_seqs_from_fasta_db  # get_seqs_from_fasta.py\n",
      "43. from module_afa_to_nex import nex_to_afa, delete_extra_mesquite_lines  # nex_to_fa.py\n",
      "44. import getpass  # run_iqtree_on_cipres.py\n",
      "45. from time import sleep  # run_iqtree_on_cipres.py\n",
      "46. from string import Template  # run_iqtree_on_cipres.py\n",
      "47. from ete3 import Tree, TreeStyle, TextFace  # test_ete3_reroot.py\n",
      "48. from module_afa_to_nex import nex_to_afa, afa_to_nex, delete_extra_mesquite_lines  # re-order_taxa_nex.py\n",
      "49. from parse_mod_num import update_mod_num_alphabetic  # rm_seq_man.py\n",
      "50. from misc_functions import launch, query_yes_no  # rm_seq_man.py\n",
      "51. from realign_nex import realign_nex  # rm_seq_man.py\n",
      "52. from module_align_to_profile_iter import do_align_iteratively  # align_to_profile_iter.py\n",
      "53. from module_amoebae_nex_to_hmm import nex_to_hmm  # nex_to_hmm.py\n",
      "54. import copy  # rough_translation.py\n",
      "55. from misc_functions import get_abbrev_fa_record_text_from_obj  # interpret_ncoils_fasta_output.py\n",
      "56. from PyPDF2 import PdfFileWriter, PdfFileReader  # add_filenames_to_pdfs.py\n",
      "57. import io  # add_filenames_to_pdfs.py\n",
      "58. from reportlab.pdfgen import canvas  # add_filenames_to_pdfs.py\n",
      "59. from reportlab.lib.pagesizes import letter  # add_filenames_to_pdfs.py\n",
      "60. import datetime  # find_human_contam_in_plasmo_reads.py\n",
      "61. import warnings  # find_human_contam_in_plasmo_reads.py\n",
      "62. from Bio import BiopythonExperimentalWarning  # find_human_contam_in_plasmo_reads.py\n",
      "63. from Bio.Blast import NCBIXML  # find_human_contam_in_plasmo_reads.py\n",
      "64. from nex_to_fa import nex_to_fa  # all_nex_to_fa_and_afa.py\n",
      "65. from module_afa_to_nex import delete_extra_mesquite_lines  # get_residue_numbers_for_position.py\n",
      "66. import numpy as np  # get_residue_numbers_for_position.py\n",
      "67. from Bio.SeqRecord import SeqRecord  # get_residue_numbers_for_position.py\n",
      "68. import collections  # get_residue_numbers_for_position.py\n",
      "69. import module_dacksify_pos_hmmer_hits  # get_residue_numbers_for_position.py\n",
      "70. from module_amoebae_phylo_clas import ModelInfoFromCSV  # setup_pairwise_rooting_analysis2.py\n",
      "71. from search_alignment_space import get_type_seqs_dict, get_nodes_of_interest,\\  # setup_pairwise_rooting_analysis2.py\n",
      "72. get_corresponding_node  # setup_pairwise_rooting_analysis2.py\n",
      "73. from module_amoebae import mask_nex2  # setup_pairwise_rooting_analysis2.py\n",
      "74. from module_amoebae_constrain_mb import constrain_mb_with_tree  # setup_pairwise_rooting_analysis2.py\n",
      "75. import module_search_scaffolds  # search_scaffolds.py\n",
      "76. from module_mask_nex import mask_nex  # mask_nex.py\n",
      "77. from module_afa_to_nex import afa_to_nex, nex_to_afa, delete_extra_mesquite_lines  # realign_nex.py\n",
      "78. import pylab  # phylo_signal_finder.py\n",
      "79. from random import shuffle  # test_iqtree_constraint_interpretation.py\n",
      "80. import unittest  # test_iqtree_constraint_interpretation.py\n",
      "81. import pandas as pd  # module_similarity_score.py\n",
      "82. import module_amoebae  # module_amoebae_search.py\n",
      "83. from module_amoebae_srchresfile import SrchResFile  # module_amoebae_search.py\n",
      "84. import module_amoebae_column_header_lists  # module_amoebae_search.py\n",
      "85. from module_amoebae_run_searches import get_query_list_from_file,\\  # module_amoebae_search.py\n",
      "86. get_db_list_from_file, get_out_query_list_path, get_out_db_list_path,\\  # module_amoebae_search.py\n",
      "87. determine_search_method, search_result_filepath, run_any_search,\\  # module_amoebae_search.py\n",
      "88. run_all_searches, get_out_hmm_path, get_query_subdir  # module_amoebae_search.py\n",
      "89. from module_search_scaffolds import split_tblastn_hits_into_separate_genes,\\  # module_amoebae_search.py\n",
      "90. get_hit_seq_record_and_coord, get_hit_seq_record_and_coord2, get_cluster_range  # module_amoebae_search.py\n",
      "91. from Bio.Blast import Record  # module_search_scaffolds.py\n",
      "92. from run_exonerate import ExonerateLocusResult, get_subseq_from_nucl,\\  # module_search_scaffolds.py\n",
      "93. run_exonerate_as_subprocess  # module_search_scaffolds.py\n",
      "94. from search_alignment_space import get_corresponding_node  # replace_nodes_in_tree.py\n",
      "95. import module_add_to_db  # module_add_to_queries_test.py\n",
      "96. import statistics  # module_amoebae_select_seqs.py\n",
      "97. from module_paralogue_counter import get_seq_obj_from_srch_res_csv_info  # module_amoebae_select_seqs.py\n",
      "98. from module_amoebae_phylo_clas import ModelInfoFromCSV,\\  # module_amoebae_select_seqs.py\n",
      "99. get_clade_name_from_model, code_names_in_ali, quote_tree, code_tree,\\  # module_amoebae_select_seqs.py\n",
      "100. uncode_tree, uncode_tree_obj  # module_amoebae_select_seqs.py\n",
      "101. from module_paralogue_counter import add_seq_to_alignment3  # module_amoebae_select_seqs.py\n",
      "102. from module_afa_to_nex import delete_extra_mesquite_lines, afa_to_nex, nex_to_afa, nex_to_phylip  # module_amoebae_select_seqs.py\n",
      "103. from Bio.Align import MultipleSeqAlignment  # module_amoebae_select_seqs.py\n",
      "104. from ete3 import Tree, faces, AttrFace, TreeStyle, NodeStyle, TextFace  # module_amoebae_select_seqs.py\n",
      "105. from module_amoebae_select_seqs import get_clade_name_from_model2,\\  # module_amoebae_select_positions.py\n",
      "106. get_nodes_of_interest, get_list_of_leaf_names_for_node, TaxonomicInfo,\\  # module_amoebae_select_positions.py\n",
      "107. get_taxonomic_info, define_nodestyles_dict_for_colourcoding,\\  # module_amoebae_select_positions.py\n",
      "108. define_textface_for_labeling_stem, get_corresponding_node,\\  # module_amoebae_select_positions.py\n",
      "109. get_ml_tree_branch_lengths, get_branch_length_info, reduce_alignment  # module_amoebae_select_positions.py\n",
      "110. import matplotlib.pyplot as plt  # generate_sankey_diagram.py\n",
      "111. from matplotlib.sankey import Sankey  # generate_sankey_diagram.py\n",
      "112. from visualize_trees import get_nodes_with_paralogues  # visualize_trees_test.py\n",
      "113. from module_amoebae_get_datatype import get_datatype_for_sequence_string  # test_module_amoebae_get_datatype.py\n",
      "114. from test_module_amoebae_get_datatype_testseqs import testseq1  # test_module_amoebae_get_datatype.py\n",
      "115. from get_alt_topos import get_total_num_topos_for_n_taxa,\\  # test_get_alt_topos.py\n",
      "116. get_all_alt_topologies,\\  # test_get_alt_topos.py\n",
      "117. get_all_unique_unrooted_bifurcating_topologies_for_n_taxa,\\  # test_get_alt_topos.py\n",
      "118. trees, get_polytomy_for_treenode  # test_get_alt_topos.py\n",
      "119. from module_amoebae_select_seqs import get_ml_tree_branch_lengths  # search_alignment_space.py\n",
      "120. from module_amoebae import find_input_file_in_parent_directory  # search_alignment_space.py\n",
      "121. import platform  # search_alignment_space.py\n",
      "122. import sys, os  # get_nonredun_import_statements_for_amoebae.py\n",
      "123. from math import factorial  # get_alt_topos.py\n",
      "124. from itertools import product  # get_alt_topos.py\n",
      "125. from module_afa_to_nex import nex_to_afa, afa_to_nex, determine_alphabet  # replace_seqs.py\n",
      "126. from module_add_to_db import make_blast_db  # replace_seqs.py\n",
      "127. from Bio import SearchIO  # replace_seqs.py\n",
      "128. from module_paralogue_counter import add_seq_to_alignment3,\\  # module_amoebae_phylo_clas.py\n",
      "129. modify_seq_descr_for_tree  # module_amoebae_phylo_clas.py\n",
      "130. from module_amoebae_name_replace import write_afa_with_code_names,\\  # module_amoebae_phylo_clas.py\n",
      "131. codenames_nex, write_newick_tree_with_coded_names  # module_amoebae_phylo_clas.py\n",
      "132. from get_alt_topos import get_all_alt_topologies, get_polytomy_for_treenode  # module_amoebae_phylo_clas.py\n",
      "133. from module_amoebae_name_replace import get_conversion_dict_from_table  # module_amoebae_prune.py\n",
      "134. write_newick_tree_with_uncoded_names,\\  # module_amoebae_prune.py\n",
      "135. write_newick_tree_with_coded_names  # module_amoebae_prune.py\n",
      "136. from ete3 import Tree, TreeStyle, Tree, TextFace, add_face_to_node  # module_amoebae_prune.py\n",
      "137. from visualize_trees import translate_int_node_names_to_support, visualize_tree  # module_amoebae_prune.py\n",
      "138. import matplotlib  # module_amoebae_plot.py\n",
      "139. from module_amoebae import get_seqs_from_fasta_db, get_subseq_from_fasta_db  # module_amoebae_srchresfile.py\n",
      "140. from module_search_scaffolds import get_blastp_hit_seq_obj_and_coord, get_tblastn_hit_seq_obj_and_coord  # module_amoebae_srchresfile.py\n",
      "141. from module_afa_to_nex import nex_to_afa, afa_to_nex, delete_extra_mesquite_lines, nex_to_phylip, nex_to_mbnex  # module_amoebae_name_replace.py\n",
      "142. import module_amoebae_srchresfile  # module_amoebae_srchresfile_test.py\n",
      "143. import smtplib  # module_eml.py\n",
      "144. from email.mime.multipart import MIMEMultipart  # module_eml.py\n",
      "145. from email.mime.text import MIMEText  # module_eml.py\n",
      "146. from ete3 import Tree, NodeStyle, TreeStyle, TextFace  # visualize_trees.py\n",
      "147. from matplotlib.backends.backend_pdf import PdfPages  # visualize_trees.py\n",
      "148. import matplotlib.colors as mc  # visualize_trees.py\n",
      "149. import colorsys  # visualize_trees.py\n",
      "150. from module_boots_on_mb import mbcontre_to_newick_w_probs  # visualize_trees.py\n",
      "151. from matplotlib.pyplot import imread  # visualize_trees.py\n",
      "152. from search_alignment_space import get_type_seqs_dict, get_nodes_of_interest, get_clade_name_from_model2  # visualize_trees.py\n",
      "153. from Bio import AlignIO, SeqIO  # module_paralogue_counter.py\n",
      "154. from module_afa_to_nex import afa_to_nex, delete_extra_mesquite_lines  # module_paralogue_counter.py\n",
      "155. from module_similarity_score import get_similarity_score, get_score_dataframe_from_file  # module_paralogue_counter.py\n",
      "156. import gffutils  # module_paralogue_counter.py\n",
      "157. from module_amoebae import get_seq_obj_from_srch_res_csv_info,\\  # module_paralogue_counter.py\n",
      "158. get_hit_range_from_hsp_ranges  # module_paralogue_counter.py\n",
      "159. from generate_sankey_diagram import generate_sankey  # module_paralogue_counter.py\n",
      "160. from generate_histogram_plot import generate_histogram,\\  # module_paralogue_counter.py\n",
      "161. generate_double_histogram, generate_bar_chart  # module_paralogue_counter.py\n",
      "\n",
      "Running output script to test import statements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./get_nonredun_import_statments_for_amoebae_output_793.py\", line 51, in <module>\n",
      "    from ete3 import Tree, TreeStyle, TextFace\n",
      "ImportError: cannot import name 'TreeStyle'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "amoebae check_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import some basic python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "import glob\n",
    "from Bio.Blast import NCBIXML\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "#sys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))\n",
    "sys.path.append('/opt/notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download peptide and nucleotide sequences for specific genomes.\n",
    "\n",
    "Let's download the predicted peptide sequences, genomic assembly (nucleotide\n",
    "sequences of assembled chromosomes), and annotation files (in GFF3 format) for the following eukaryotes from NCBI:\n",
    "\n",
    "- *Arabidopsis thaliana*\n",
    "- *Trypanosoma brucei*\n",
    "- *Dictyostelium discoideum*\n",
    "- *Allomyces macrogynus*\n",
    "- *Saccharomyces cerevisiae*\n",
    "\n",
    "\n",
    "This could take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initiate a list of file paths for downloaded sequence and annotation files.\n",
    "datafile_path_list = []\n",
    "\n",
    "# Define a dictionary of source URLs and new filenames for sequence and annotation files.\n",
    "datafile_dict = {\"Athaliana_database.faa.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/735/GCF_000001735.4_TAIR10.1/GCF_000001735.4_TAIR10.1_protein.faa.gz\",\n",
    "                 \"Athaliana_database.fna.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/735/GCF_000001735.4_TAIR10.1/GCF_000001735.4_TAIR10.1_genomic.fna.gz\",\n",
    "                 \"Athaliana_database.gff3.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/735/GCF_000001735.4_TAIR10.1/GCF_000001735.4_TAIR10.1_genomic.gff.gz\",\n",
    "                 \"Scerevisiae_database.faa.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/146/045/GCF_000146045.2_R64/GCF_000146045.2_R64_protein.faa.gz\",\n",
    "                 \"Scerevisiae_database.fna.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/146/045/GCF_000146045.2_R64/GCF_000146045.2_R64_genomic.fna.gz\",\n",
    "                 \"Scerevisiae_database.gff3.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/146/045/GCF_000146045.2_R64/GCF_000146045.2_R64_genomic.gff.gz\",\n",
    "                 \"Tbrucei_database.faa.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/295/GCF_000210295.1_ASM21029v1/GCF_000210295.1_ASM21029v1_protein.faa.gz\",\n",
    "                 \"Tbrucei_database.fna.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/295/GCF_000210295.1_ASM21029v1/GCF_000210295.1_ASM21029v1_genomic.fna.gz\",\n",
    "                 \"Tbrucei_database.gff3.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/295/GCF_000210295.1_ASM21029v1/GCF_000210295.1_ASM21029v1_genomic.gff.gz\",\n",
    "                 \"Ddiscoideum_database.faa.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/004/695/GCF_000004695.1_dicty_2.7/GCF_000004695.1_dicty_2.7_protein.faa.gz\",\n",
    "                 \"Ddiscoideum_database.fna.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/004/695/GCF_000004695.1_dicty_2.7/GCF_000004695.1_dicty_2.7_genomic.fna.gz\",\n",
    "                 \"Ddiscoideum_database.gff3.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/004/695/GCF_000004695.1_dicty_2.7/GCF_000004695.1_dicty_2.7_genomic.gff.gz\",\n",
    "                 \"Amacrogynus_database.faa.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/151/295/GCA_000151295.1_A_macrogynus_V3/GCA_000151295.1_A_macrogynus_V3_protein.faa.gz\",\n",
    "                 \"Amacrogynus_database.fna.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/151/295/GCA_000151295.1_A_macrogynus_V3/GCA_000151295.1_A_macrogynus_V3_genomic.fna.gz\",\n",
    "                 \"Amacrogynus_database.gff3.gz\": \"ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/151/295/GCA_000151295.1_A_macrogynus_V3/GCA_000151295.1_A_macrogynus_V3_genomic.gff.gz\"\n",
    "          }\n",
    "\n",
    "# Make a new temporary directory to store data files.\n",
    "temp_db_dir_name = 'temporary_db_dir'\n",
    "assert not os.path.isdir(temp_db_dir_name)\n",
    "os.mkdir(temp_db_dir_name)\n",
    "\n",
    "# Download all the data files via NCBI's FTP server.\n",
    "for filename in datafile_dict.keys():\n",
    "    url = datafile_dict[filename]\n",
    "    filepath = os.path.join(temp_db_dir_name, filename)\n",
    "    if not os.path.isfile(filepath):\n",
    "        subprocess.call(['curl', url, '--output', filepath])\n",
    "        subprocess.call(['gunzip', filepath])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating a data directory structure.\n",
    "To generate a directory structure and spreadsheets for storing formatted sequence files\n",
    "and metadata for each sequence file, use the 'mkdatadir' command (this takes a\n",
    "single argument which is the full path that you want your new directory to be\n",
    "written to):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \n",
      "        To allow AMOEBAE scripts to locate your new data directory, change the\n",
      "        value of the root_amoebae_data_dir variable in the settings.py file to\n",
      "        the full path to the directory:\n",
      "\n",
      "        AMOEBAE_Data\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export DATADIR=\"AMOEBAE_Data\"\n",
    "amoebae mkdatadir $DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will prompt you to set the 'root\\_amoebae\\_data\\_dir' variable in the\n",
    "settings.py file to this new directory path so that AMOEBAE scripts can locate\n",
    "your files.\n",
    "\n",
    "This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMOEBAE_Data\n"
     ]
    }
   ],
   "source": [
    "# Check that the path indicated in the settings file is correct.\n",
    "import settings\n",
    "print(settings.root_amoebae_data_dir)\n",
    "assert settings.root_amoebae_data_dir == \"AMOEBAE_Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing databases for searching.\n",
    "To generate a directory structure and spreadsheets for storing formatted sequence files\n",
    "and metadata for each sequence file, use the 'mkdatadir' command (this takes a\n",
    "single argument which is the full path that you want your new directory to be\n",
    "written to).\n",
    "\n",
    "This will take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 02:25:26\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Amacrogynus_database.faa\n",
      "New DB title:  AMOEBAE_Data/Genomes/Amacrogynus_database.faa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 19447 sequences in 2.01947 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Amacrogynus_database.faa...    done.\n",
      "Indexed 19447 sequences (19447 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Amacrogynus_database.faa.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 02:25:31\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Amacrogynus_database.fna\n",
      "New DB title:  AMOEBAE_Data/Genomes/Amacrogynus_database.fna\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 101 sequences in 1.27208 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Amacrogynus_database.fna...    done.\n",
      "Indexed 101 sequences (101 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Amacrogynus_database.fna.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 02:35:44\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Athaliana_database.faa\n",
      "New DB title:  AMOEBAE_Data/Genomes/Athaliana_database.faa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 48265 sequences in 4.09677 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Athaliana_database.faa...    done.\n",
      "Indexed 48265 sequences (48265 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Athaliana_database.faa.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 02:35:54\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Athaliana_database.fna\n",
      "New DB title:  AMOEBAE_Data/Genomes/Athaliana_database.fna\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 7 sequences in 2.20203 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Athaliana_database.fna...    done.\n",
      "Indexed 7 sequences (7 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Athaliana_database.fna.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 06:21:15\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Ddiscoideum_database.faa\n",
      "New DB title:  AMOEBAE_Data/Genomes/Ddiscoideum_database.faa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 13315 sequences in 1.54682 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Ddiscoideum_database.faa...    done.\n",
      "Indexed 13315 sequences (13315 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Ddiscoideum_database.faa.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 06:21:19\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Ddiscoideum_database.fna\n",
      "New DB title:  AMOEBAE_Data/Genomes/Ddiscoideum_database.fna\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 41 sequences in 0.815412 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Ddiscoideum_database.fna...    done.\n",
      "Indexed 41 sequences (41 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Ddiscoideum_database.fna.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 06:24:24\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Scerevisiae_database.faa\n",
      "New DB title:  AMOEBAE_Data/Genomes/Scerevisiae_database.faa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 6002 sequences in 0.558493 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Scerevisiae_database.faa...    done.\n",
      "Indexed 6002 sequences (6002 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Scerevisiae_database.faa.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 06:24:26\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Scerevisiae_database.fna\n",
      "New DB title:  AMOEBAE_Data/Genomes/Scerevisiae_database.fna\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 17 sequences in 0.223812 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Scerevisiae_database.fna...    done.\n",
      "Indexed 17 sequences (17 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Scerevisiae_database.fna.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 06:24:46\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Tbrucei_database.faa\n",
      "New DB title:  AMOEBAE_Data/Genomes/Tbrucei_database.faa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 9822 sequences in 0.90941 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Tbrucei_database.faa...    done.\n",
      "Indexed 9822 sequences (9822 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Tbrucei_database.faa.ssi\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/20/2020 06:24:49\n",
      "New DB name:   /opt/notebooks/notebooks/AMOEBAE_Data/Genomes/Tbrucei_database.fna\n",
      "New DB title:  AMOEBAE_Data/Genomes/Tbrucei_database.fna\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 11 sequences in 0.409424 seconds.\n",
      "\n",
      "\n",
      "Creating SSI index for AMOEBAE_Data/Genomes/Tbrucei_database.fna...    done.\n",
      "Indexed 11 sequences (11 names).\n",
      "SSI index written to file AMOEBAE_Data/Genomes/Tbrucei_database.fna.ssi\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for X in temporary_db_dir/*; do amoebae add_to_dbs $X; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amacrogynus_database.faa\n",
      "Amacrogynus_database.fna\n",
      "Athaliana_database.faa\n",
      "Athaliana_database.fna\n",
      "Ddiscoideum_database.faa\n",
      "Ddiscoideum_database.fna\n",
      "Scerevisiae_database.faa\n",
      "Scerevisiae_database.fna\n",
      "Tbrucei_database.faa\n",
      "Tbrucei_database.fna\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# List the databases now accessible by AMOEBAE.\n",
    "amoebae list_dbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take some time, because an SQL database will be generated to store information from the GFF3 annotation file (this is what is will be listed in the genome info CSV file).\n",
    "\n",
    "When this is finished, copy the name of the .sql file to the row for the corresponding genomic assembly (.fna) file in the column with the header \"Annotations file\", and do the same for the row describing the corresponding peptide sequence (.faa) file. This allows the correct GFF3 file to be used for the assembly (.fna file) and predicted amino acid sequences (.faa).\n",
    "\n",
    "Next you must manually modify the spreadsheet so that it has the correct metadata for this sequence file. Open it with Excel or Open Office, and enter the following information:\n",
    "- Fill the \"Superbranch\", \"Supergroup\", \"Group\", and \"Species (if applicable)\" fields with the values \"Diaphoretickes\", \"Archaeplastida\", \"Embryophyta\", and \"Arabidopsis thaliana\", respectively. These are arbitrary selected taxonomic groups to which Arabidopsis belongs (Adl et al., 2018), but if note similar taxonomic information for each genome you download then it will help to keep organized.\n",
    "- Fill the \"Taxon\" field with the abbreviation \"Athaliana\". This is used for abbreviating names when necessary.\n",
    "- Fill in the other fields as you see fit. It is recommended that you keep track of where you downloaded files from, and which assembly you used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter your email to access the NCBI protein database via NCBI Entrez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your email address here: lael@ualberta.ca\n"
     ]
    }
   ],
   "source": [
    "Entrez.email = input(\"Enter your email address here: \")  # Tell NCBI who you are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download single-sequence queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with NCBI sequence accessions as keys and filenames to write\n",
    "# the corresponding sequences to as values.\n",
    "query_dict = {\"NP_194077.1\": \"AP1beta_Athaliana_NP_194077.1_query.faa\",\n",
    "              \"NP_851058.1\": \"AP2alpha_Athaliana_NP_851058.1_query.faa\",\n",
    "              \"NP_974895.1\": \"AP2mu_Athaliana_NP_974895.1_query.faa\",\n",
    "              \"NP_175219.1\": \"AP2sigma_Athaliana_NP_175219.1_query.faa\",\n",
    "              \"NP_566961.1\": \"Sec12_Athaliana_NP_566961.1_query.faa\",\n",
    "              \"NP_200929.1\": \"SNAP33_Athaliana_NP_200929.1_query.faa\",\n",
    "              \"NP_193449.1\": \"Rab2_Athaliana_NP_193449.1_query.faa\"\n",
    "          }\n",
    "\n",
    "# Make a new temporary directory to store sequence files.\n",
    "temp_query_dir_name = 'temporary_query_dir'\n",
    "assert not os.path.isdir(temp_query_dir_name), \"\"\"Directory already exists.\"\"\"\n",
    "os.mkdir(temp_query_dir_name)\n",
    "\n",
    "# Loop over keys in the query_dict dictionary.\n",
    "for accession in query_dict.keys():\n",
    "    # Retrieve the corresponding filename from the dictionary.\n",
    "    filename = query_dict[accession]\n",
    "    # Only download sequences that have not already been downloaded.\n",
    "    if not os.path.isfile(filename):\n",
    "        # Download the sequence from NCBI via Entrez, using the Biopython module.\n",
    "        net_handle = Entrez.efetch(db=\"protein\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
    "        out_handle = open(os.path.join(temp_query_dir_name, filename), \"w\")\n",
    "        out_handle.write(net_handle.read())\n",
    "        out_handle.close()\n",
    "        net_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare single-sequence queries for searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries must be formatted and stored in a similar manner to genomic data files. The query files will include FASTA files containing one sequence and FASTA files containing multiple sequences.\n",
    "Now we are going to generate the query files and add them to your AMOEBAE_Data/ Queries directory, in a similar way to how we added genomic data files to the AMOEBA E_Data/Genomes directory. Since you already downloaded all the peptide sequences for Arabidopsis thaliana, you can retrieve these from your downloaded data using one of the scripts in the amoebae/misc_scripts folder. First, let’s generate a query for the A. thaliana AP-1/2 beta subunit(s), which is a component of both the AP-1 and AP-2 complexes, using a representative sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: AP1beta_Athaliana_NP_194077.1_query.faa\n",
      "\tQuery title: AP1beta\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n",
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: AP2alpha_Athaliana_NP_851058.1_query.faa\n",
      "\tQuery title: AP2alpha\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n",
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: AP2mu_Athaliana_NP_974895.1_query.faa\n",
      "\tQuery title: AP2mu\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n",
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: AP2sigma_Athaliana_NP_175219.1_query.faa\n",
      "\tQuery title: AP2sigma\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n",
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: Rab2_Athaliana_NP_193449.1_query.faa\n",
      "\tQuery title: Rab2\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n",
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: SNAP33_Athaliana_NP_200929.1_query.faa\n",
      "\tQuery title: SNAP33\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n",
      "Information added to spreadsheet 0_query_info.csv:\n",
      "\tFilename: Sec12_Athaliana_NP_566961.1_query.faa\n",
      "\tQuery title: Sec12\n",
      "\tQuery source description: Athaliana\n",
      "\tQuery taxon (species if applicable): -\n",
      "\tData type: prot\n",
      "\tFile type: faa\n",
      "\tDate added: 2020/02/20\n",
      "\tCitation: ?\n",
      "\tQuery database filename (if applicable): -\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for QUERYFILE in temporary_query_dir/*.faa; do amoebae add_to_queries $QUERYFILE; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP1beta_Athaliana_NP_194077.1_query.faa\n",
      "AP2alpha_Athaliana_NP_851058.1_query.faa\n",
      "AP2mu_Athaliana_NP_974895.1_query.faa\n",
      "AP2sigma_Athaliana_NP_175219.1_query.faa\n",
      "Rab2_Athaliana_NP_193449.1_query.faa\n",
      "SNAP33_Athaliana_NP_200929.1_query.faa\n",
      "Sec12_Athaliana_NP_566961.1_query.faa\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "amoebae list_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the information in the spreadsheet (AMOEBAE_Data/Queries/0_query_in fo.csv). Make sure that the query titles AP1beta, AP2alpha, AP2mu, and AP2sigma are entered in the appropriate rows in the \"Query title\" column. This allows multiple query files to be associated with the same query title if they are to be used to search for the same set of homologues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct alignments for profile searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of NCBI sequence accessions and filenames to which to write the corresponding sequences.\n",
    "query_title_dict = {\"AP1beta\": \"NP_194077.1,CBI34366.3,XP_015631818.1,XP_024516549.1,OAE33273.1\",\n",
    "                    \"AP2alpha\": \"NP_851058.1,XP_002270388.1,XP_015631820.1,PTQ35247.1,XP_024525508.1\",\n",
    "                    \"AP2mu\": \"NP_974895.1,XP_002281297.1,XP_015627628.1,OAE25965.1,XP_002973295.1\",\n",
    "                    \"AP2sigma\": \"NP_175219.1,XP_015618362.1,PTQ50284.1,XP_002275803.1,XP_024518676.1\",\n",
    "                    \"Sec12\": \"NP_566961.1,XP_002262948.1,XP_015647566.1,OAE21792.1,XP_024530559.1\",\n",
    "                    \"SNAP33\": \"NP_200929.1,XP_002284486.1,AAW82752.1,EFJ31467.1,OAE29824.1,XP_006270633.1,XP_006010378.1,XP_006625751.1,NP_001080510.1,XP_020370357.1,XP_015181699.1,XP_031769811.1\",\n",
    "                    \"Rab2\": \"NP_193449.1,XP_003635585.2,XP_015626284.1,XP_002965710.1,PTQ28228.1\"\n",
    "                   }\n",
    "                    \n",
    "\n",
    "# Make a new temporary directory to store sequence files.\n",
    "temp_alignment_dir_name = 'temporary_alignment_dir'\n",
    "assert not os.path.isdir(temp_alignment_dir_name), \"\"\"Directory already exists.\"\"\"\n",
    "os.mkdir(temp_alignment_dir_name)\n",
    "\n",
    "# Download query sequences and write to multiple-sequence FASTA files.\n",
    "for query_title in query_title_dict.keys():\n",
    "    accession_list_string = query_title_dict[query_title]\n",
    "    filepath = os.path.join(temp_alignment_dir_name, query_title + '_hmm1.faa')\n",
    "    if not os.path.isfile(filepath):\n",
    "        net_handle = Entrez.efetch(db=\"protein\", id=accession_list_string, rettype=\"fasta\", retmode=\"text\")\n",
    "        out_handle = open(filepath, \"w\")\n",
    "        out_handle.write(net_handle.read())\n",
    "        out_handle.close()\n",
    "        net_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "AP1beta_hmm1 5 seqs, max length 920, avg  length 901\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     11 MB(1%)  Iter   1   25.00%  Align node       \r",
      "00:00:00     15 MB(1%)  Iter   1   50.00%  Align node\r",
      "00:00:00     16 MB(1%)  Iter   1   75.00%  Align node\r",
      "00:00:00     16 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:00     16 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:00     16 MB(1%)  Iter   1   20.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   1   40.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   1   60.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   1   80.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:00     16 MB(1%)  Iter   2   33.33%  Refine tree   \r",
      "00:00:00     16 MB(1%)  Iter   2   66.67%  Refine tree\r",
      "00:00:00     16 MB(1%)  Iter   2  100.00%  Refine tree\r",
      "00:00:00     16 MB(1%)  Iter   2  100.00%  Refine tree\r\n",
      "00:00:00     16 MB(1%)  Iter   2   20.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   2   40.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   2   60.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   2   80.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   2  100.00%  Root alignment\r",
      "00:00:00     16 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     16 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     16 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter   8   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   8  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter   9   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter   9  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  10   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  10  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  11   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  11  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  12   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  12  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  13   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  13  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  14   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  14  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  15   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  15  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  16   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  16  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  17   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  17  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  18   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  18  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  19   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  19  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  20   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  20  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  20  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  21   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  21  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  22   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  22  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  23   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  23  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  24   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  24  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  25   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  25  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  26   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  26  100.00%  Refine biparts\r\n",
      "00:00:00     16 MB(1%)  Iter  27   28.57%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27   42.86%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27   57.14%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27   71.43%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27   85.71%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27  100.00%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27  114.29%  Refine biparts\r",
      "00:00:00     16 MB(1%)  Iter  27  100.00%  Refine biparts\r\n",
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "AP2alpha_hmm1 5 seqs, max length 1045, avg  length 1019\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     11 MB(1%)  Iter   1   25.00%  Align node       \r",
      "00:00:00     16 MB(1%)  Iter   1   50.00%  Align node\r",
      "00:00:00     16 MB(1%)  Iter   1   75.00%  Align node\r",
      "00:00:00     17 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:00     17 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:00     17 MB(1%)  Iter   1   20.00%  Root alignment\r",
      "00:00:00     17 MB(1%)  Iter   1   40.00%  Root alignment\r",
      "00:00:00     17 MB(1%)  Iter   1   60.00%  Root alignment\r",
      "00:00:00     17 MB(1%)  Iter   1   80.00%  Root alignment\r",
      "00:00:00     17 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:00     17 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:00     17 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     17 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter   8   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   8  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter   9   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter   9  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  10   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  10  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  11   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  11  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  12   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  12  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  13   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  13  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  14   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  14  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  15   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  15  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  16   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  16  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  17   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  17  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  18   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  18  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  19   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  19  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  20   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  20  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  21   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  21  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  22   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  22  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  23   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  23  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  23  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  24   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  24  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  25   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  25  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  26   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  26  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  27   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  27  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  28   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  28  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  29   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  29  100.00%  Refine biparts\r\n",
      "00:00:00     17 MB(1%)  Iter  30   28.57%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30   42.86%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30   57.14%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30   71.43%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30   85.71%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30  100.00%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30  114.29%  Refine biparts\r",
      "00:00:00     17 MB(1%)  Iter  30  100.00%  Refine biparts\r\n",
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "AP2mu_hmm1 5 seqs, max length 441, avg  length 439\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     11 MB(1%)  Iter   1   25.00%  Align node       \r",
      "00:00:00     13 MB(1%)  Iter   1   50.00%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1   75.00%  Align node\r",
      "00:00:01     13 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:01     14 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:01     14 MB(1%)  Iter   1   20.00%  Root alignment\r",
      "00:00:01     14 MB(1%)  Iter   1   40.00%  Root alignment\r",
      "00:00:01     14 MB(1%)  Iter   1   60.00%  Root alignment\r",
      "00:00:01     14 MB(1%)  Iter   1   80.00%  Root alignment\r",
      "00:00:01     14 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:01     14 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:01     14 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:01     14 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter   8   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   8  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter   9   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter   9  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  10   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  10  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  11   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  11  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  12   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  12  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  13   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  13  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  14   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  14  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  15   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  15  100.00%  Refine biparts\r\n",
      "00:00:01     14 MB(1%)  Iter  16   28.57%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16   42.86%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16   57.14%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16   71.43%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16   85.71%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16  100.00%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16  114.29%  Refine biparts\r",
      "00:00:01     14 MB(1%)  Iter  16  100.00%  Refine biparts\r\n",
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "AP2sigma_hmm1 5 seqs, max length 142, avg  length 142\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     10 MB(1%)  Iter   1   25.00%  Align node       \r",
      "00:00:00     12 MB(1%)  Iter   1   50.00%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1   75.00%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:00     12 MB(1%)  Iter   1   20.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1   40.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1   60.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1   80.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:00     12 MB(1%)  Iter   2   33.33%  Refine tree   \r",
      "00:00:00     12 MB(1%)  Iter   2   66.67%  Refine tree\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Refine tree\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Refine tree\r\n",
      "00:00:00     12 MB(1%)  Iter   2   20.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2   40.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2   60.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2   80.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     12 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6  114.29%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:01     12 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7  114.29%  Refine biparts\r",
      "00:00:01     12 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "Rab2_hmm1 5 seqs, max length 213, avg  length 209\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     10 MB(1%)  Iter   1   25.00%  Align node       \r",
      "00:00:00     12 MB(1%)  Iter   1   50.00%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1   75.00%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:00     12 MB(1%)  Iter   1   20.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1   40.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1   60.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1   80.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:00     12 MB(1%)  Iter   2   33.33%  Refine tree   \r",
      "00:00:00     12 MB(1%)  Iter   2   66.67%  Refine tree\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Refine tree\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Refine tree\r\n",
      "00:00:00     12 MB(1%)  Iter   2   20.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2   40.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2   60.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2   80.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Root alignment\r",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     12 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     12 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   8   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   8  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter   9   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter   9  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter  10   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  10  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter  11   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  11   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  11  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter  11  100.00%  Refine biparts\r\n",
      "00:00:00     12 MB(1%)  Iter  12   28.57%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12   42.86%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12   57.14%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12   71.43%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12   85.71%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12  100.00%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12  114.29%  Refine biparts\r",
      "00:00:00     12 MB(1%)  Iter  12  100.00%  Refine biparts\r\n",
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "SNAP33_hmm1 12 seqs, max length 436, avg  length 252\n",
      "00:00:00     10 MB(1%)  Iter   1    1.28%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    1.28%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     11 MB(1%)  Iter   1    9.09%  Align node       \r",
      "00:00:00     12 MB(1%)  Iter   1   18.18%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1   27.27%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1   36.36%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1   45.45%  Align node\r",
      "00:00:00     12 MB(1%)  Iter   1   54.55%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1   63.64%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1   72.73%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1   81.82%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1   90.91%  Align node\r",
      "00:00:00     14 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:00     14 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:00     14 MB(1%)  Iter   1    8.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   16.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   25.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   33.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   41.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   50.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   58.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   66.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   75.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   83.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1   91.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:00     14 MB(1%)  Iter   2   10.00%  Refine tree   \r",
      "00:00:00     14 MB(1%)  Iter   2   20.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2   30.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2   40.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2   50.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2   60.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2   70.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Refine tree\r\n",
      "00:00:00     14 MB(1%)  Iter   2    8.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   16.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   25.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   33.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   41.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   50.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   58.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   66.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   75.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   83.33%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   91.67%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     14 MB(1%)  Iter   3    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   4    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   5    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   6    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   7    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   8    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   9    9.52%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   14.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   19.05%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   23.81%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   33.33%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   38.10%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   47.62%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   52.38%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   61.90%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   66.67%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   76.19%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   80.95%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   90.48%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   95.24%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9  104.76%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9  100.00%  Refine biparts\r\n",
      "\n",
      "MUSCLE v3.8.31 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "Sec12_hmm1 5 seqs, max length 408, avg  length 394\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 1\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 1\r\n",
      "00:00:00     10 MB(1%)  Iter   1    6.67%  K-mer dist pass 2\r",
      "00:00:00     10 MB(1%)  Iter   1  100.00%  K-mer dist pass 2\r\n",
      "00:00:00     11 MB(1%)  Iter   1   25.00%  Align node       \r",
      "00:00:00     13 MB(1%)  Iter   1   50.00%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1   75.00%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1  100.00%  Align node\r",
      "00:00:00     13 MB(1%)  Iter   1  100.00%  Align node\r\n",
      "00:00:00     13 MB(1%)  Iter   1   20.00%  Root alignment\r",
      "00:00:00     13 MB(1%)  Iter   1   40.00%  Root alignment\r",
      "00:00:00     13 MB(1%)  Iter   1   60.00%  Root alignment\r",
      "00:00:00     13 MB(1%)  Iter   1   80.00%  Root alignment\r",
      "00:00:00     13 MB(1%)  Iter   1  100.00%  Root alignment\r",
      "00:00:00     13 MB(1%)  Iter   1  100.00%  Root alignment\r\n",
      "00:00:00     13 MB(1%)  Iter   2   33.33%  Refine tree   \r",
      "00:00:00     13 MB(1%)  Iter   2   66.67%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2  133.33%  Refine tree\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Refine tree\r\n",
      "00:00:00     14 MB(1%)  Iter   2   20.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   40.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   60.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2   80.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Root alignment\r",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     14 MB(1%)  Iter   2  100.00%  Root alignment\r\n",
      "00:00:00     14 MB(1%)  Iter   3   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   3  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   4   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   4  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   5   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   5  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   6   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   6  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   7   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   7  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   8   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   8  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter   9   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter   9  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  10   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  10  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  11   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  11  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  12   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  12  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  13   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  13  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  14   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  14  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  15   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15   57.14%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15   71.43%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15   85.71%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15  100.00%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15  114.29%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  15  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  16   28.57%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  16   42.86%  Refine biparts\r",
      "00:00:00     14 MB(1%)  Iter  16  100.00%  Refine biparts\r\n",
      "00:00:00     14 MB(1%)  Iter  16  100.00%  Refine biparts\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for X in temporary_alignment_dir/*.faa; do amoebae align_fa $X --output_format fasta; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visually inspect alignments\n",
    "Alignments used as queries should be visually inspected to make sure that there are no obvious errors in the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for QUERYFILE in temporary_alignment_dir/*.afaa; do amoebae add_to_queries $QUERYFILE; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare query alignments for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for QUERYFILE in temporary_alignment_dir/*.afaa; do amoebae add_to_queries $QUERYFILE; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae list_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate lists of potential redundant sequences among A. thaliana peptide sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, a reciprocal-best-hit search strategy will be used. If you are using a reciprocal- best-hit search strategy, then your initial round of searches will be performed using your original queries (assembled above) to search your genomes of interest. This initial round of searches will be referred to herein as \"forward searches\", and subsequent searches using forward search hits as queries into reference genomes will be referred to as \"reverse searches\".\n",
    "\n",
    "A slight complication to this search strategy is that the NCBI RefSeq peptide sequences for the A. thaliana genome include alternative transcripts and lineage-specific inparalogues (as do other databases), implying that if these were retrieved as the top hits in the reverse searches instead of the original query sequence, then this would still potentially be a positive result. So, to properly interpret reverse search results it will be necessary to determine which sequences in our A. thaliana .faa file are redundant for our purposes. To do this we will use the get_redun_hits command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir Redundant_hits\n",
    "amoebae list_queries > Redundant_hits/queries.txt\n",
    "amoebae get_redun_hits Redundant_hits --query_list_file Redundant_hits/queries.txt --db_name Athaliana_database.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output a directory in the Redundant_hits folder with a .csv file. Open the CSV file. This file contains a summary of BLASTP or HMMer search results for searches with the specified queries into the S. cerevisiae predicted proteins. In the column with the header \"Positive/redundant (+) or negative (-) hit for queries with query title (edit this column)\", change the ’-’ to ’+’ for hits that are the original query, or redundant with the original query for the purposes of this analysis.\n",
    "It should be apparent upon inspection of the ranking of hits and comparison of the associated E-values which hits are redundant with your queries. The redundant accessions for each query (both single sequence and HMM queries for the same AP-2 subunit) should be similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify redundant sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with query titles as keys and lists of sequence IDs as values, where the IDs are for A. thaliana sequences that are redundant with the original A. thaliana query sequence.\n",
    "redun_seq_dict = {\"AP1beta\": [\"NP_194077.1\",\n",
    "                              \"NP_192877.1\",\n",
    "                              \"NP_001328014.1\",\n",
    "                              \"NP_001190701.1\"\n",
    "                              ],\n",
    "                  \"AP2alpha\": [\"NP_851058.1\",\n",
    "                               \"NP_851057.1\",\n",
    "                               \"NP_197669.1\",\n",
    "                               \"NP_001330971.1\",\n",
    "                               \"NP_001330970.1\",\n",
    "                               \"NP_001330969.1\",\n",
    "                               \"NP_197670.1\",\n",
    "                               \"NP_001330127.1\"\n",
    "                               ],\n",
    "                  \"AP2mu\": [\"NP_974895.1\",\n",
    "                            \"NP_199475.1\"\n",
    "                            ],\n",
    "                  \"AP2sigma\": [\"NP_175219.1\"\n",
    "                               ],\n",
    "                  \"Sec12\": [\"NP_566961.1\",\n",
    "                            \"NP_568738.1\",\n",
    "                            \"NP_680414.1\",\n",
    "                            \"NP_178256.1\"\n",
    "                            ],\n",
    "                  \"SNAP33\": [\"NP_200929.1\",\n",
    "                             \"NP_001332102.1\",\n",
    "                             \"NP_172842.1\",\n",
    "                             \"NP_001318998.1\",\n",
    "                             \"NP_196405.1\",\n",
    "                             \"NP_001318503.1\"\n",
    "                             ],\n",
    "                  \"Rab2\": [\"NP_193449.1\",\n",
    "                           \"NP_193450.1\",\n",
    "                           \"NP_195311.1\",\n",
    "                           \"NP_001078499.1\"\n",
    "                           ]\n",
    "                   }\n",
    "\n",
    "\n",
    "# Identify path to redundant seqs CSV file.\n",
    "redundant_seqs_csv = glob.glob(os.path.join('Redundant_hits', os.path.join('redun_hits_*', '0_redun_hits_*.csv')))[0]\n",
    "\n",
    "# Define path for new modified redundant seqs CSV file.\n",
    "redundant_seqs_csv2 = redundant_seqs_csv.rsplit(\".\", 1)[0] + '_2.csv'\n",
    "\n",
    "# Open the redundant seqs CSV file, and a new one.\n",
    "with open(redundant_seqs_csv) as infh, open(redundant_seqs_csv2, 'w') as o:\n",
    "    # Loop over lines in the CSV file.\n",
    "    for i in infh:\n",
    "        if not i.startswith(\"Query Title\"):\n",
    "            # Identify query title in line.\n",
    "            line_query_title = i.split(',')[0].strip()\n",
    "            # Identify accession/id for sequence hit represented in this row.\n",
    "            line_accession = i.split(',')[9].strip().strip('\\\"')\n",
    "            # Loop over keys (query titles) in the redundant seqs dictionary.\n",
    "            query_title_in_keys = False\n",
    "            for query_title in redun_seq_dict.keys():\n",
    "                if line_query_title == query_title:\n",
    "                    query_title_in_keys = True\n",
    "                    #print('YYY')\n",
    "                    #print(line_accession)\n",
    "                    #print(redun_seq_dict[line_query_title])\n",
    "                    # Determine whether the accession is a redundant accession.\n",
    "                    for acc in redun_seq_dict[line_query_title]:\n",
    "                        #print(line_accession, acc)\n",
    "                        if line_accession == acc:\n",
    "                            # Change the - to + so that the accession will be included in the list of redundant accessions used by AMOEBAE.\n",
    "                            i = ','.join(i.split(',')[:4]) + ',+,' + ','.join(i.split(',')[5:])\n",
    "                            break\n",
    "                # Break loop if the corresponding query title was found already.\n",
    "                if query_title_in_keys:\n",
    "                    break\n",
    "            # Check that a query title could be recognized as one that is a key in the dictionary.\n",
    "            assert query_title_in_keys, \"\"\"Could not find query title %s in dictionary.\"\"\" % line_query_title\n",
    "        # Write (modified) line to new CSV file.\n",
    "        o.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to update the 0\\_query\\_info.csv file with the correct query title for\n",
    "these, which should match those of the single-sequence queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running forward searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin searching, make a new folder to contain search results, and write text files listing the names (not full paths) of FASTA files you want to use as queries and those that you want to search in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Make a new directory to contain search results.\n",
    "mkdir AMOEBAE_Search_Results_1\n",
    "# Write query and database list files.\n",
    "amoebae list_queries > AMOEBAE_Search_Results_1/queries.txt\n",
    "amoebae list_dbs > AMOEBAE_Search_Results_1/databases.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up searches using the setup_fwd_srch command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Set up forward searches.\n",
    "amoebae setup_fwd_srch AMOEBAE_Search_Results_1\\\n",
    "                       AMOEBAE_Search_Results_1/queries.txt\\\n",
    "                       AMOEBAE_Search_Results_1/databases.txt\\\n",
    "                       --outdir AMOEBAE_Search_Results_1/fwd_srch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output a new sub-directory with a name that starts with \"fwd_srch_\". Now run the searches with this directory as input via the run_fwd_srch command. Forward search criteria may be selected at this point (view the relevant optional arguments via the -h option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run forward searches. This could take a while.\n",
    "amoebae run_fwd_srch AMOEBAE_Search_Results_1/fwd_srch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This will run BLASTP or HMMer for searches into the .faa files (depending on whether queries are single- or multi-fasta), or TBLASTN for searches into the .fna files with any single-fasta queries.\n",
    "Now we can generate a summary of the raw output files. Important criteria may be cus- tomized here as well. Specifically the forward search E-value threshold, and the maximum number of nucleotide bases allowed between TBLASTN HSPs to be considered part of the same gene (view optional arguments via the -h option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Summarize forward search results in a CSV file.\n",
    "amoebae sum_fwd_srch AMOEBAE_Search_Results_1/fwd_srch_1\\\n",
    "                     AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the resulting CSV file. Note that maximum E-value cutoffs, and other criteria were applied as specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running reverse searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to determine which of the \"forward hits\" in these search results are really specific to our original A. thaliana queries, let’s search with these hits as queries back into the A. thaliana genome (i.e., perform \"reverse\" searches).\n",
    "\n",
    "Similar to the forward searches, we need to first set up the reverse search directory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae setup_rev_srch AMOEBAE_Search_Results_1\\\n",
    "                       AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out.csv\\\n",
    "                       Athaliana_database.faa\\\n",
    "                       --outdir AMOEBAE_Search_Results_1/rev_srch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output a new directory with \"rev_srch_\" and a timestamp in the name. Run reverse searches using the path to this directory as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae run_rev_srch AMOEBAE_Search_Results_1/rev_srch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now append columns summarizing the results of these reverse searches to our CSV file. This is where the file listing redundant hits for each query title is used. Also, a criterion is applied here based on the order of magnitude difference in E-value between the original query (or redundant hits) in the reverse search results compared to other hits (if present), and this can be optionally modified (view optional arguments via the -h option).\n",
    "\n",
    "This could take a while.\n",
    "\n",
    "**Error: extra quotation marks were written to the redundant hits CSV file...**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae sum_rev_srch AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out.csv\\\n",
    "                     AMOEBAE_Search_Results_1/rev_srch_1\\\n",
    "                     --redun_hit_csv Redundant_hits/redun_hits_20200121161452/0_redun_hits_20200121161452_2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this will output a CSV file with the same path as the forward search summary CSV file, but with a \"_1\" added before the filename extension. Examine the resulting CSV file.\n",
    "You could run additional reverse searches into different files, appending columns to the same summary spreadsheet. Reverse searches into the A. thaliana peptide sequences is all that is necessary for this tutorial.\n",
    "\n",
    "Next run the interp_srchs command to do an additional interpretation of the results (if reverse searches into multiple reference databases were performed then this would be done following summarization of all the reverse searches). Again, customized criteria may be applied at this point using the optional arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae interp_srchs AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out_1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, examine the resulting CSV file to see whether the results match your expectations. You will notice that the results in this file do not account for the fact that the HMMer, BLASTP, and TBLASTN hits are redundant in many cases as might be expected if each of these search algorithms were effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting out which positive hits are redundant\n",
    "\n",
    "We need to determine which hits correspond to the same loci based on having identical accessions or being associated with the same locus in the GFF3 annotation file, or likely represent distinct paralogous gene loci based on sequence similarity in a multiple sequence alignment (see Larson et al. (2019) for explanation of how these are identified).\n",
    "To do this, first we will append a column listing what alignment to use (by default it will be the alignments that are used as queries for the corresponding query title):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae find_redun_seqs AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out_1_interp_20200122122113.csv --add_ali_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now identify distinct paralogues (use the -h option to view optional arguments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae find_redun_seqs AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out_1_interp_20200122122113_with_ali_col.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output another copy of the CSV file with additional columns. Take some time to decide whether you agree with the exclusion of some of the hits, as indicated in the appended columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting search results\n",
    "\n",
    "Finally, we can plot the results of the searches. To customize the organization of the output coulson plot, an additional input CSV file may be optionally provided here. This file simply contains the names of protein complexes in the first column and query titles for proteins that you want to include in each complex in the second column (see example file provided with this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \\\n",
    "\"AP2,AP1beta\n",
    "AP2,AP2alpha\n",
    "AP2,AP2mu\n",
    "AP2,AP2sigma\n",
    "COPII,Sec12\n",
    "SNAREs,SNAP33\n",
    "Rabs,Rab2\" > AMOEBAE_Search_Results_1/complex_info_1.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Problem: species name not automatically added to genome_info.csv..\n",
    "amoebae plot AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out_1_interp_20200122122113_with_ali_col_paralogue_count_20200122232356_2.csv\\\n",
    "             --complex_info AMOEBAE_Search_Results_1/complex_info_1.csv\\\n",
    "             --out_pdf AMOEBAE_Search_Results_1/plot.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the resulting PDF files. Your coulson plot should look something like that in Figure 1. Compare with the results of searches for AP-2 subunits published by Manna et al. (2013), Barlow et al. (2014), and Larson et al. (2019). You will need to customize formatting of coulson plots output by the ’plot’ command using software such as Adobe Illustrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AMOEBAE_Search_Results_1/plot_coulson_both.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1: A coulson plot summarizing similarity search results for AP-2 complex subunits in Trypanosoma brucei gambiense and Saccharomyces cerevisiae peptide and nucleotide se- quences using Arabidopsis thaliana queries and Hidden Markov Models generated from align- ments of embryophyte orthologues. BLASTP and TBLASTN were used to search peptide and nucleotide sequences, respectively, with single sequence queries, and the HMMer3 pack- age was used to perform profile searches. Subplot sectors with blue fill indicate that one or more sequences were found to meet the search criteria applied (with the number being indicated within each subplot sector). Note that the ancestral eukaryotic AP-1 and AP-2 complexes shared a single beta subunit (Dacks et al., 2008). This is why identified \"AP1beta\" orthologues are shown as a component of the AP-2 complex here, even though T. brucei lacks an AP-2 complex (Manna et al., 2013). These results are comparable to the relevant results published by Manna et al. (2013), Barlow et al. (2014), and Larson et al. (2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation and re-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be clear that AMOEBAE identifies \"positive\" and \"negative\" results simply by applying criteria that the user specifies. So, it is entirely the users responsibility to select appropriate criteria and interpret the results critically.\n",
    "\n",
    "Points to consider regarding interpretation of the results of the analysis in this tutorial include the following:\n",
    "- The BLASTP and HMMer searches (both followed by reverse BLASTP searches) yielded the same results in this analysis.\n",
    "- The TBLASTN searches were able to identify all of the genes represented by the peptide sequences identified by BLASTP and HMMer searches.\n",
    "- A TBLASTN hit in the A. thaliana chromosome 5 (NC_003076.8) met the forward and reverse search criteria, but was excluded because the translation of the region that aligned to the query was only 50 amino acids long (this sequence also contained stop codons). If you look on the NCBI genome browser for A. thaliana you will see that this region on chromosome 5 (as indicated in the summary CSV file) corresponds to a pseudogene for AP-2 sigma with the gene ID AT5G42568.\n",
    "- The two A. thaliana AP-1/2 beta paralogues and the two S. cerevisiae paralogues are brassicalid and fungal inparalogues, respectively, which arose from independent gene duplications. Phylogenetic analysis would be required to determine this (see Larson et al. (2019) and Barlow et al. (2014)).\n",
    "- An Arabidopsis thaliana AP-2 mu splice variant was excluded after running the ’find _redun_seqs’ command, because it was found to be encoded by the same gene as the other splice variant based on information in the GFF3 annotation file.\n",
    "- An A. thaliana AP-2 alpha gene was excluded after running the ’find_redun_seqs’ command, because it shows over 98% identity with the other AP-2 alpha gene. The summary CSV file indicates which file contains an alignment of these two sequences (see Larson et al. (2019) for relevant discussion).\n",
    "\n",
    "If the analysis in this tutorial were a project you were working on for publication, then upon completing the above analysis steps you work would have only just begun. AMOEBAE merely finds sequences that match your specified search criteria, which may or may not be sufficient to accurately identify homologues of interest. Careful inspection of the summary CSV file will reveal that minor adjustments to the search criteria would cause the analysis to yield different results. Moreover, there are many different possibilities that would lead to innacurate results based on the criteria applied in the above analysis. A comprehensive discussion of this is beyond the scope of this tutorial, but one obvious example would be if an identified sequence contained a domain that was not present in the query sequence, causing sequences to be retrieved in the reverse search with no homology to the original query. Therefore, it is recommended that you commit to an iterative approach to analysis involving adjustment of search criteria and re-analysis to include sequences that you know are homologues of interest, but to exclude those that you know are not homologues of interest.\n",
    "\n",
    "To generate an alignment of similar sequences identified using AMOEBAE, use the ’csv_to _fasta’ command to generate FASTA files for alignment, and then align using your preferred software (e.g., MUSCLE or MAFFT). For visually assessing the sequences for possible issues such as contrasting domain topologies, you may wish to generate FASTA files including all your forward search results for each query title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae csv_to_fasta AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out_1_interp_20200122122113_with_ali_col_paralogue_count_20200122232356_2.csv\\\n",
    "                     --all_hits --split_by_query_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to run a phylognetic analysis, you may wish to generate a FASTA file with only those sequences that match all your search criteria, and with abbreviated sequence headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae csv_to_fasta AMOEBAE_Search_Results_1/fwd_srch_1_sum.csv_out_1_interp_20200122122113_with_ali_col_paralogue_count_20200122232356_2.csv\\\n",
    "                     --abbrev --split_by_query_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete search output files (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#rm *blastp_search_output.txt\n",
    "#rm *blastp_search_output.xml\n",
    "#rm *reverse_query.faa\n",
    "#rm *blastp_reverse_search_output.txt\n",
    "#rm *blastp_reverse_search_output.xml\n",
    "#rm 0_summary_of_forward_blastp_searches.csv\n",
    "#rm 0_summary_of_forward_and_reverse_blastp_searches.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go from here?\n",
    "\n",
    "You can customize this notebook to search with different queries in different genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Barlow, L.D., Dacks, J.B., Wideman, J.G., 2014. From all to (nearly) none: Tracing adaptin evolution in Fungi. Cellular Logistics 4, e28114. https://doi.org/10.4161/cl.28114\n",
    "\n",
    "Hirst, J., D. Barlow, L., Francisco, G.C., Sahlender, D.A., Seaman, M.N.J., Dacks, J.B., Robinson, M.S., 2011. The Fifth Adaptor Protein Complex. PLoS Biology 9, e1001170. https://doi.org/10.1371/journal.pbio.1001170\n",
    "\n",
    "Larson, R.T., Dacks, J.B., Barlow, L.D., 2019. Recent gene duplications dominate evolutionary dynamics of adaptor protein complex subunits in embryophytes. Traffic 20, 961–973. https://doi.org/10.1111/tra.12698\n",
    "\n",
    "Manna, P.T., Kelly, S., Field, M.C., 2013. Adaptin evolution in kinetoplastids and emergence of the variant surface glycoprotein coat in African trypanosomatids. Molecular Phylogenetics and Evolution 67, 123–128. https://doi.org/10.1016/j.ympev.2013.01.002\n",
    "\n",
    "Robinson, M.S., 2004. Adaptable adaptors for coated vesicles. Trends in Cell Biology 14, 167–174. https://doi.org/10.1016/j.tcb.2004.02.002\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
