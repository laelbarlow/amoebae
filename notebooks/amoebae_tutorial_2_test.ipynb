{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will walk you through a preliminary similarity searching analysis making use of scripts in the AMOEBAE toolkit. While AMOEBAE was not originally written to be used via the command line, Jupyter notebooks provide an easy means of guiding new users through an example analysis with limited need for manual input. The end result of running this code successfully is a spreadsheet summarizing results of similarity searches, as well as a plot to visualize the results.\n",
    "\n",
    "As a simple example, we will consider the the distribution of orthologues of subunits of the Adaptor Protein (AP) 2 vesicle adaptor complex, and several other membrane-trafficking proteins, in five model eukaryotes: the plant *Arabidopsis thaliana*, the yeast *Saccharomyces cerevisiae*, the fungus *Allomyces macrogynus*, the amoeba *Dictyostelium discoideum*, and the pathogenic protist *Trypanosoma brucei*. AP-2 subunits are homologous to subunits of other AP complexes (Robinson, 2004; Hirst et al., 2011), and published work has traced their evolution among plants (Larson et al., 2019), Fungi (Barlow et al., 2014), and trypanosomatid parasites (Manna et al., 2013). Thus, the protein subunits of the AP-2 complex provide a useful test of similarity searching methods to distinguish between orthologues and paralogues, which can be compared to the results of previous studies. In addition, the membrane trafficking proteins Sec12 (a component of the COPII vesicle coat complex), SNAP33 (a Qbc-SNARE), and Rab2 (a small GTPase) are included to further explore the potential sources of error involved in identification of orthologous proteins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this tutorial\n",
    "\n",
    "\n",
    "-  Perform similarity searches using the BLASTP, TBLASN, HMMer algorithms simultaneously using AMOBEAE scripts.\n",
    "\n",
    "-  Apply a reciprocal-best-hit search strategy using AMOEBAE code.\n",
    "\n",
    "- Practice interpreting similarity search results obtained using AMOEBAE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Before running this code, you will need to have set up AMOEBAE according to the instructions in the main documentation file here (which you likely have already done): [AMOEBAE_documentation.pdf](\n",
    "https://github.com/laelbarlow/amoebae/blob/master/documentation/AMOEBAE_documentation.pdf).\n",
    "\n",
    "- MacOS or Linux operating system (or possibly a work-around on windows, although this has not been tested).\n",
    "\n",
    "- Approximately 3GB of storage space.\n",
    "\n",
    "- An internet connection.\n",
    "\n",
    "- At least an hour of your time (the code in this notebook will take approximately 60 minutes to run).\n",
    "\n",
    "- Running the code in this notebook is more computationally intensive than webbrowsing for example, so if you are running this on a laptop computer, then make sure it is connected to an electrical outlet.\n",
    "\n",
    "## Testing\n",
    "If you wish to simply run all the code in this notebook for testing purposes:\n",
    "\n",
    "- First, modify the cell in the section labeled \"Enter your email to access the NCBI protein database via NCBI Entrez\" below such that the value of Entrez.email is hard-coded as your email address.\n",
    "\n",
    "- Then select \"Cell\" > \"Run All\" from the Jupyter menu above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the amoebae script\n",
    "\n",
    "The directory containing the amoebae executable script must be present in your $PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "printf \"\\nThis is the directory that this notebook is run in:\\n\"\n",
    "pwd\n",
    "echo\n",
    "printf \"\\nThis is the path to the amoebae executable script that will be used:\\n\"\n",
    "command -v amoebae\n",
    "#echo\n",
    "#printf \"\\nThese are all the paths in the \\$PATH variable:\\n\"\n",
    "#tr ':' '\\n' <<< \"$PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that dependencies are installed\n",
    "\n",
    "You should have already pulled the amoebae git repository to your computer as described in the main documentation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# This command simply prints the versions of some dependencies which are now available for use by amoebae.\n",
    "amoebae check_depend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# This command tests all the import statements in amoebae modules.\n",
    "amoebae check_imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some basic python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "import glob\n",
    "from Bio.Blast import NCBIXML\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update PATH so that additional modules can be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory (the main amoebae repository directory) to the $PATH.\n",
    "sys.path.append('..')\n",
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record the specific version of AMOEBAE code used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record git repository version information.\n",
    "wd = !pwd\n",
    "script_dir = wd[0] \n",
    "git_hash = str(subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=script_dir).strip())\n",
    "git_branch = str(subprocess.check_output([\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=script_dir).strip())  \n",
    "print('\\nGit repository (code) version: ' + git_hash + ' (branch name: ' + git_branch + ')\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a subdirectory to store output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir amoebae_tutorial_2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd amoebae_tutorial_2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate a data directory structure\n",
    "To generate a directory structure and spreadsheets for storing formatted sequence files\n",
    "and metadata for each sequence file, use the 'mkdatadir' command (this takes a\n",
    "single argument which is the full path that you want your new directory to be\n",
    "written to):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATADIR=AMOEBAE_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae mkdatadir $DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will prompt you to set the 'root\\_amoebae\\_data\\_dir' variable in the\n",
    "settings.py file to this new directory path so that AMOEBAE scripts can locate\n",
    "your files.\n",
    "\n",
    "This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that the path indicated in the settings file is correct.\n",
    "import settings\n",
    "print(settings.root_amoebae_data_dir)\n",
    "assert settings.root_amoebae_data_dir == \"AMOEBAE_Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up queries\n",
    "\n",
    "## Enter your email to access the NCBI protein database via NCBI Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out this line and use the line at the bottom of this cell instead, if you want to run all cells at once.\n",
    "#Entrez.email = input(\"Enter your email address here: \")  # Tell NCBI who you are.\n",
    "\n",
    "# Use the line at the top of this cell instead.\n",
    "#Entrez.email = \"yourname@email.com\"\n",
    "Entrez.email = \"lael@ualberta.ca\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download single-sequence queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define a dictionary with NCBI sequence accessions as keys and filenames to write\n",
    "# the corresponding sequences to as values.\n",
    "query_dict = {\"NP_194077.1\": \"AP1beta_Athaliana_NP_194077.1_query.faa\",\n",
    "              \"NP_851058.1\": \"AP2alpha_Athaliana_NP_851058.1_query.faa\",\n",
    "              \"NP_974895.1\": \"AP2mu_Athaliana_NP_974895.1_query.faa\",\n",
    "              \"NP_175219.1\": \"AP2sigma_Athaliana_NP_175219.1_query.faa\",\n",
    "              \"NP_566961.1\": \"Sec12_Athaliana_NP_566961.1_query.faa\",\n",
    "              \"NP_200929.1\": \"SNAP33_Athaliana_NP_200929.1_query.faa\",\n",
    "              \"NP_193449.1\": \"Rab2_Athaliana_NP_193449.1_query.faa\"\n",
    "          }\n",
    "\n",
    "# Make a new temporary directory to store sequence files.\n",
    "temp_query_dir_name = 'temporary_query_dir'\n",
    "if not os.path.isdir(temp_query_dir_name):\n",
    "    os.mkdir(temp_query_dir_name)\n",
    "\n",
    "# Loop over keys in the query_dict dictionary.\n",
    "for accession in query_dict.keys():\n",
    "    # Retrieve the corresponding filename from the dictionary.\n",
    "    filename = query_dict[accession]\n",
    "    filepath = os.path.join(temp_query_dir_name, filename)\n",
    "    # Only download sequences that have not already been downloaded.\n",
    "    if not os.path.isfile(filepath):\n",
    "        # Download the sequence from NCBI via Entrez, using the Biopython module.\n",
    "        net_handle = Entrez.efetch(db=\"protein\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
    "        out_handle = open(filepath, \"w\")\n",
    "        out_handle.write(net_handle.read())\n",
    "        out_handle.close()\n",
    "        net_handle.close()\n",
    "    # Check that the sequence was actually downloaded.\n",
    "    assert os.path.isfile(filepath), \"\"\"The sequence with the following accession could not be downloaded from NCBI: %s\\n\n",
    "    Try re-running this cell.\"\"\" % accession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare single-sequence queries for searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries must be formatted and stored in a similar manner to genomic data files. The query files will include FASTA files containing one sequence and FASTA files containing multiple sequences.\n",
    "Now we are going to generate the query files and add them to your AMOEBAE_Data/ Queries directory, in a similar way to how we added genomic data files to the AMOEBAE_Data/Genomes directory. Since you already downloaded all the peptide sequences for Arabidopsis thaliana, you can retrieve these from your downloaded data using one of the scripts in the amoebae/misc_scripts folder. First, let’s generate a query for the A. thaliana AP-1/2 beta subunit(s), which is a component of both the AP-1 and AP-2 complexes, using a representative sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SECONDS=0\n",
    "\n",
    "for QUERYFILE in temporary_query_dir/*.faa; do amoebae add_to_queries $QUERYFILE; done\n",
    "\n",
    "ELAPSED=\"Preparing query sequences for searching took the following amount of time: $(($SECONDS / 3600))hrs $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec\"\n",
    "echo $ELAPSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "amoebae list_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct alignments for profile similarity searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define a dictionary of NCBI sequence accessions and filenames to which to write the corresponding sequences.\n",
    "query_title_dict = {\"AP1beta\": \"NP_194077.1,CBI34366.3,XP_015631818.1,XP_024516549.1,OAE33273.1\",\n",
    "                    \"AP2alpha\": \"NP_851058.1,XP_002270388.1,XP_015631820.1,PTQ35247.1,XP_024525508.1\",\n",
    "                    \"AP2mu\": \"NP_974895.1,XP_002281297.1,XP_015627628.1,OAE25965.1,XP_002973295.1\",\n",
    "                    \"AP2sigma\": \"NP_175219.1,XP_015618362.1,PTQ50284.1,XP_002275803.1,XP_024518676.1\",\n",
    "                    \"Sec12\": \"NP_566961.1,XP_002262948.1,XP_015647566.1,OAE21792.1,XP_024530559.1\",\n",
    "                    \"SNAP33\": \"NP_200929.1,XP_002284486.1,AAW82752.1,EFJ31467.1,OAE29824.1,XP_006270633.1,XP_006010378.1,XP_006625751.1,NP_001080510.1,XP_020370357.1,XP_015181699.1,XP_031769811.1\",\n",
    "                    \"Rab2\": \"NP_193449.1,XP_003635585.2,XP_015626284.1,XP_002965710.1,PTQ28228.1\"\n",
    "                   }\n",
    "                    \n",
    "\n",
    "# Make a new temporary directory to store sequence files.\n",
    "temp_alignment_dir_name = 'temporary_alignment_dir'\n",
    "assert not os.path.isdir(temp_alignment_dir_name), \"\"\"Directory already exists.\"\"\"\n",
    "os.mkdir(temp_alignment_dir_name)\n",
    "\n",
    "# Download query sequences and write to multiple-sequence FASTA files.\n",
    "for query_title in query_title_dict.keys():\n",
    "    accession_list_string = query_title_dict[query_title]\n",
    "    filepath = os.path.join(temp_alignment_dir_name, query_title + '_hmm1.faa')\n",
    "    if not os.path.isfile(filepath):\n",
    "        net_handle = Entrez.efetch(db=\"protein\", id=accession_list_string, rettype=\"fasta\", retmode=\"text\")\n",
    "        out_handle = open(filepath, \"w\")\n",
    "        out_handle.write(net_handle.read())\n",
    "        out_handle.close()\n",
    "        net_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "SECONDS=0\n",
    "\n",
    "for X in temporary_alignment_dir/*.faa; do amoebae align_fa $X --output_format fasta; done\n",
    "\n",
    "ELAPSED=\"Aligning FASTA files took the following amount of time: $(($SECONDS / 3600))hrs $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec\"\n",
    "echo $ELAPSED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the AMOEBAE_Data/Genomes/0_genome_info.csv file, the AMOEBAE_Data/Queries/0_query_info.csv file contains information about each query file, which can be manually edited. One of the most important pieces of information is the \"Query title\". Different query files, such as a single FASTA sequence and an HMM, can have the same Query title if they are to be used to search for homologues or orthologues of the same protein(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define author name for this notebook.\n",
    "author_name = \"\"\n",
    "\n",
    "# Define title of this notebook.\n",
    "notebook_title = 'amoebae_tutorial_2'.replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "import os\n",
    "from string import Template\n",
    "\n",
    "# Write a latex template file for converting this notebook to latex (as an intermediate to PDF).\n",
    "latex_template_string = Template(r\"\"\"\n",
    "((*- extends 'article.tplx' -*))\n",
    "\n",
    "((* block author *))\n",
    "\\author{$an}\n",
    "((* endblock author *))\n",
    "\n",
    "((* block title *))\n",
    "\\title{$nt}\n",
    "((* endblock title *))\n",
    "\"\"\")\n",
    "latex_file_contents =\\\n",
    "latex_template_string.substitute(an=author_name,\n",
    "                                 nt=notebook_title\n",
    "                                )\n",
    "latex_template_file_path = 'latex_template.tplx'\n",
    "with open(latex_template_file_path, 'w') as o:\n",
    "    o.write(latex_file_contents)\n",
    "\n",
    "# Convert notebook to PDF (with latex as an intermediate to process bibtex citations, etc.).\n",
    "!jupyter nbconvert ../amoebae_tutorial_2.ipynb --to pdf --template {latex_template_file_path}\n",
    "\n",
    "# Remove latex template file and bibtex file.\n",
    "os.remove(latex_template_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "559px",
    "width": "543px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
